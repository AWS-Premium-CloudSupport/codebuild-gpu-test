name: GPU Test Workflow

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build:
    runs-on:
      - codebuild-gpu-test-${{ github.run_id }}-${{ github.run_attempt }}
      - image:381492037974.dkr.ecr.us-east-1.amazonaws.com/codebuild-cuda12-test:latest
      - instance-size:gpu_large

    steps:
      - uses: actions/checkout@v3
      
      - name: System Info
        run: |
          echo "=== System Information ==="
          uname -a
          cat /etc/os-release
          
      - name: Environment Info
        run: |
          echo "=== Environment Variables ==="
          env | grep -i cuda
          echo "=== CUDA Path ==="
          ls -l /usr/local/cuda*
          
      - name: GPU Info
        run: |
          echo "=== GPU Information ==="
          nvidia-smi
          echo "=== CUDA Version ==="
          nvcc --version
          
      - name: Run CUDA Tests
        run: |
          echo "=== Running Basic CUDA Test ==="
          ./cuda_test
          echo "=== Running Vector Addition CUDA Test ==="
          ./vector_add
          
      - name: Compile and Run New CUDA Program
        run: |
          echo "=== Creating new CUDA program ==="
          cat > matrix_mul.cu << 'EOL'
          #include <stdio.h>
          #include <cuda_runtime.h>
          
          __global__ void matrixMul(int *a, int *b, int *c, int n) {
              int row = blockIdx.y * blockDim.y + threadIdx.y;
              int col = blockIdx.x * blockDim.x + threadIdx.x;
              
              if (row < n && col < n) {
                  int sum = 0;
                  for (int k = 0; k < n; k++) {
                      sum += a[row * n + k] * b[k * n + col];
                  }
                  c[row * n + col] = sum;
              }
          }
          
          int main() {
              int n = 4;  // Small matrix size for testing
              size_t size = n * n * sizeof(int);
              
              int *h_a = (int *)malloc(size);
              int *h_b = (int *)malloc(size);
              int *h_c = (int *)malloc(size);
              
              // Initialize matrices
              for (int i = 0; i < n * n; i++) {
                  h_a[i] = 1;
                  h_b[i] = 2;
              }
              
              int *d_a, *d_b, *d_c;
              cudaMalloc(&d_a, size);
              cudaMalloc(&d_b, size);
              cudaMalloc(&d_c, size);
              
              cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
              cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);
              
              dim3 threadsPerBlock(2, 2);
              dim3 numBlocks((n + threadsPerBlock.x - 1) / threadsPerBlock.x,
                           (n + threadsPerBlock.y - 1) / threadsPerBlock.y);
              
              matrixMul<<<numBlocks, threadsPerBlock>>>(d_a, d_b, d_c, n);
              
              cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);
              
              printf("Matrix Multiplication Result:\\n");
              for (int i = 0; i < n; i++) {
                  for (int j = 0; j < n; j++) {
                      printf("%d ", h_c[i * n + j]);
                  }
                  printf("\\n");
              }
              
              cudaFree(d_a);
              cudaFree(d_b);
              cudaFree(d_c);
              free(h_a);
              free(h_b);
              free(h_c);
              
              return 0;
          }
          EOL
          
          echo "=== Compiling Matrix Multiplication Program ==="
          nvcc matrix_mul.cu -o matrix_mul
          
          echo "=== Running Matrix Multiplication Program ==="
          ./matrix_mul
