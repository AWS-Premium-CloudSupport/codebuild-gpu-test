name: GPU Test Workflow

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build:
    runs-on:
      - codebuild-gpu-test-${{ github.run_id }}-${{ github.run_attempt }}
      - image:381492037974.dkr.ecr.us-east-1.amazonaws.com/codebuild-cuda12-test:latest
      - instance-size:gpu_large

    steps:
      - uses: actions/checkout@v3
      
      - name: Start Docker daemon
        run: |
          echo "=== Docker Configuration ==="
          cat /etc/docker/daemon.json
          echo "=== Starting Docker Daemon ==="
          dockerd --storage-driver=vfs &
          sleep 10
          docker info || true
      
      - name: System Info
        run: |
          echo "=== System Information ==="
          uname -a
          cat /etc/os-release
          
      - name: GPU and CUDA Info
        run: |
          echo "=== GPU Information ==="
          nvidia-smi
          echo "=== CUDA Version ==="
          nvcc --version
          echo "=== CUDA Path ==="
          ls -l /usr/local/cuda*
          
      - name: Test CUDA Program
        run: |
          echo "=== Running CUDA Test Program ==="
          /tmp/test
          
      - name: Create and Run New CUDA Program
        run: |
          echo "=== Creating new CUDA program ==="
          cat > test.cu << 'EOL'
          #include <stdio.h>
          __global__ void hello_kernel() {
              printf("Hello from GPU! (Thread %d)\n", threadIdx.x);
          }
          int main() {
              hello_kernel<<<1, 4>>>();
              cudaDeviceSynchronize();
              return 0;
          }
          EOL
          
          echo "=== Compiling CUDA program ==="
          nvcc test.cu -o test
          
          echo "=== Running CUDA program ==="
          ./test
